{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collectl Dsk Log Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionalities\n",
    "- Plot disk I/O utilization graphs.\n",
    "\n",
    "## Input\n",
    "Log files are read from a directory in `../data`. This directory is assumed to have the following structure:\n",
    "```\n",
    "logs/\n",
    "  [node-1]/\n",
    "    collectl.tar.gz\n",
    "  ...\n",
    "  [node-n]/\n",
    "    collectl.tar.gz\n",
    "```\n",
    "A tarball `collectl.tar.gz` contains log files. The log file extension identifies the type of resource monitored:\n",
    "- `.cpu.gz`: CPU monitoring log file.\n",
    "- `.numa.gz`: memory monitoring log file.\n",
    "- `.dsk.gz`: disk I/O monitoring log file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## GENERAL\n",
    "# Name of the directory in `../data`\n",
    "EXPERIMENT_DIRNAME = \"BuzzBlogBenchmark_[TIMESTAMP]\"\n",
    "# Ramp up duration (in sec)\n",
    "RAMP_UP_DURATION = 180\n",
    "# Ramp down duration (in sec)\n",
    "RAMP_DOWN_DURATION = 180\n",
    "\n",
    "########## DISK I/O\n",
    "# Analyzed metric (options: \"name\", \"reads\", \"rmerge\", \"rkbytes\", \"waitr\", \"writes\", \"wmerge\", \"wkbytes\", \"waitw\",\n",
    "# \"request\", \"quelen\", \"wait\", \"svctim\", \"util\")\n",
    "COLLECTL_DSK_METRIC = \"writes\"\n",
    "# Filter disks\n",
    "COLLECTL_DISKS = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\")))\n",
    "from utils.utils import *\n",
    "\n",
    "experiment_dirpath = os.path.join(os.path.abspath(\"\"), \"..\", \"data\", EXPERIMENT_DIRNAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Parsing & Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build data frame\n",
    "dsk = pd.concat([df[2] for df in get_collectl_dsk_df(experiment_dirpath)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data frames\n",
    "if COLLECTL_DISKS:\n",
    "    dsk = dsk[(dsk[\"hw_no\"].isin(COLLECTL_DISKS))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract experiment information\n",
    "start_time = get_experiment_start_time(experiment_dirpath)\n",
    "node_names = get_node_names(experiment_dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Re) Build columns\n",
    "dsk[\"timestamp\"] = dsk.apply(lambda r: (r[\"timestamp\"] - start_time).total_seconds(), axis=1)\n",
    "dsk[\"window\"] = dsk.apply(lambda r: int(r[\"timestamp\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Re) Create index\n",
    "dsk.set_index(\"timestamp\", inplace=True)\n",
    "dsk.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disk Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot disk utilization (1-sec granularity)\n",
    "fig = plt.figure(figsize=(24, len(node_names) * 12))\n",
    "for (i, node_name) in enumerate(node_names):\n",
    "    df = dsk[(dsk[\"node_name\"] == node_name)]\n",
    "    df = df.groupby([\"window\"])[COLLECTL_DSK_METRIC].mean()\n",
    "    ax = fig.add_subplot(len(node_names), 1, i + 1)\n",
    "    ax.set_xlim((df.index.min(), df.index.max()))\n",
    "    ax.grid(alpha=0.75)\n",
    "    df.plot(ax=ax, kind=\"line\", title=\"%s - Disk Utilization\" % node_name, xlabel=\"Time (seconds)\",\n",
    "            ylabel=\"%s\" % COLLECTL_DSK_METRIC, grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## LOCAL CONFIG\n",
    "# Minimum time (in seconds)\n",
    "MIN_TIME = None\n",
    "# Maximum time (in seconds)\n",
    "MAX_TIME = None\n",
    "\n",
    "# Plot disk utilization (millisec granularity)\n",
    "if MIN_TIME and MAX_TIME:\n",
    "    fig = plt.figure(figsize=(24, len(node_names) * 12))\n",
    "    for (i, node_name) in enumerate(node_names):\n",
    "        df = dsk[(dsk[\"node_name\"] == node_name)]\n",
    "        df = df[(df.index >= MIN_TIME) & (df.index <= MAX_TIME)]\n",
    "        df = df.groupby([\"timestamp\", \"hw_no\"])[COLLECTL_DSK_METRIC].max()\n",
    "        df = df.unstack()\n",
    "        ax = fig.add_subplot(len(node_names), 1, i + 1)\n",
    "        ax.set_xlim((df.index.min(), df.index.max()))\n",
    "        ax.grid(alpha=0.75)\n",
    "        df.plot(ax=ax, kind=\"line\", title=\"%s - Disk Utilization\" % node_name, xlabel=\"Time (seconds)\",\n",
    "                ylabel=\"%s\" % COLLECTL_DSK_METRIC, grid=True, legend=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
