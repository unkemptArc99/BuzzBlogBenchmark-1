{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Request Log Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionalities\n",
    "- Display a summary of requests and their performance metrics.\n",
    "\n",
    "## Input\n",
    "Log files are read from a directory in `../data`. This directory is assumed to have the following structure:\n",
    "```\n",
    "logs/\n",
    "  [node-1]/\n",
    "    loadgen[0-9]*.tar.gz\n",
    "  ...\n",
    "  [node-n]/\n",
    "    loadgen[0-9]*.tar.gz\n",
    "```\n",
    "A tarball `loadgen[0-9]*.tar.gz` contains a request log file named `loadgen.log`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## GENERAL\n",
    "# Name of the directory in `../data`\n",
    "EXPERIMENT_DIRNAME = \"BuzzBlogBenchmark_[TIMESTAMP]\"\n",
    "# Ramp up duration (in sec)\n",
    "RAMP_UP_DURATION = 180\n",
    "# Ramp down duration (in sec)\n",
    "RAMP_DOWN_DURATION = 60\n",
    "\n",
    "########## LATENCY\n",
    "# Bin size\n",
    "LATENCY_BIN_IN_MS = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\")))\n",
    "from utils.utils import *\n",
    "\n",
    "experiment_dirpath = os.path.join(os.path.abspath(\"\"), \"..\", \"data\", EXPERIMENT_DIRNAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Parsing & Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build data frame\n",
    "requests = pd.concat([df[2] for df in get_loadgen_df(experiment_dirpath)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract experiment information\n",
    "start_time = get_experiment_start_time(experiment_dirpath)\n",
    "max_latency_in_s = int(requests[\"latency\"].max()) + 1.0\n",
    "n_request_types = len(requests.type.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Re) Build columns\n",
    "requests[\"timestamp\"] = requests.apply(lambda r: (r[\"timestamp\"] - start_time).total_seconds(), axis=1)\n",
    "requests[\"window_1000\"] = requests.apply(lambda r: int(r[\"timestamp\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Re) Create index\n",
    "requests.set_index(\"timestamp\", inplace=True)\n",
    "requests.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Status of Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 6))\n",
    "ax = fig.gca()\n",
    "df = requests.groupby([\"status\"]).count()[\"method\"]\n",
    "df.plot(ax=ax, kind=\"pie\", title=\"Number of successful/failed requests\", xlabel=\"\", ylabel=\"\", legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 6))\n",
    "ax = fig.gca()\n",
    "df = requests[requests[\"status\"] == \"failed\"].groupby([\"status_code\"]).count()[\"method\"]\n",
    "df.plot(ax=ax, kind=\"pie\", title=\"HTTP status code of failed requests\", xlabel=\"\", ylabel=\"\", legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type of Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 6))\n",
    "ax = fig.gca()\n",
    "df = requests.groupby([\"rw\"]).count()[\"method\"]\n",
    "df.plot(ax=ax, kind=\"pie\", title=\"Number of read/write requests\", xlabel=\"\", ylabel=\"\", legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 12))\n",
    "ax = fig.gca()\n",
    "ax.grid(alpha=0.75)\n",
    "df = requests.groupby([\"type\", \"status\"]).count()[\"method\"].unstack().fillna(0)\n",
    "df.plot(ax=ax, kind=\"bar\", stacked=True, title=\"Number of requests of each type\", xlabel=\"\", ylabel=\"Requests (count)\",\n",
    "        color={\"failed\": \"red\", \"successful\": \"blue\"}, legend=True, grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request Latency Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24, 12))\n",
    "ax = fig.gca(xlabel=\"Latency (milliseconds)\", ylabel=\"Requests (count)\")\n",
    "ax.grid(alpha=0.75)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlim((0, (1000 // LATENCY_BIN_IN_MS) * max_latency_in_s))\n",
    "ax.set_xticks(range(int((1000 // LATENCY_BIN_IN_MS) * max_latency_in_s) + 1))\n",
    "ax.set_xticklabels(range(0, (int((1000 // LATENCY_BIN_IN_MS) * max_latency_in_s) + 1) * LATENCY_BIN_IN_MS, LATENCY_BIN_IN_MS))\n",
    "df = requests[requests[\"status\"] == \"successful\"]\n",
    "df = df[(df.index >= RAMP_UP_DURATION) & (df.index <= requests.index.max() - RAMP_DOWN_DURATION)]\n",
    "df[\"latency_bin\"] = df.apply(lambda r: int(r[\"latency\"] * 1000 // LATENCY_BIN_IN_MS), axis=1)\n",
    "df[\"latency_bin\"].plot(ax=ax, kind=\"hist\",\n",
    "        title=\"Latency Distribution of Successful Requests Excluding Ramping Periods\",\n",
    "        bins=range(int((1000 // LATENCY_BIN_IN_MS) * max_latency_in_s)), grid=True)\n",
    "p999 = df[\"latency\"].quantile(0.999) * 1000\n",
    "p50 = df[\"latency\"].quantile(0.50) * 1000\n",
    "ax.axvline(x=p50 / LATENCY_BIN_IN_MS, ls=\"dotted\", lw=5, color=\"darkorange\")\n",
    "ax.text(x=p50 / LATENCY_BIN_IN_MS, y=100, s=\" P50\", fontsize=22, color=\"darkorange\")\n",
    "ax.axvline(x=p999 / LATENCY_BIN_IN_MS, ls=\"dotted\", lw=5, color=\"darkorange\")\n",
    "ax.text(x=p999 / LATENCY_BIN_IN_MS, y=100, s=\" P99.9\", fontsize=22, color=\"darkorange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24, n_request_types * 12))\n",
    "for (i, request_type) in enumerate(requests.type.unique()):\n",
    "  ax = fig.add_subplot(n_request_types, 1, i + 1)\n",
    "  ax.grid(alpha=0.75)\n",
    "  ax.set_yscale(\"log\")\n",
    "  ax.set_xlim((0, (1000 // LATENCY_BIN_IN_MS) * max_latency_in_s))\n",
    "  ax.set_xticks(range(int((1000 // LATENCY_BIN_IN_MS) * max_latency_in_s) + 1))\n",
    "  ax.set_xticklabels(range(0, (int((1000 // LATENCY_BIN_IN_MS) * max_latency_in_s) + 1) * LATENCY_BIN_IN_MS, LATENCY_BIN_IN_MS))\n",
    "  df = requests[(requests[\"status\"] == \"successful\") & (requests[\"type\"] == request_type)]\n",
    "  df = df[(df.index >= RAMP_UP_DURATION) & (df.index <= requests.index.max() - RAMP_DOWN_DURATION)]\n",
    "  df[\"latency_bin\"] = df.apply(lambda r: int(r[\"latency\"] * 1000 // LATENCY_BIN_IN_MS), axis=1)\n",
    "  df[\"latency_bin\"].plot(ax=ax, kind=\"hist\", title=request_type, xlabel=\"Latency (milliseconds)\",\n",
    "      ylabel=\"Requests (count)\",\n",
    "      bins=range(int((1000 // LATENCY_BIN_IN_MS) * max_latency_in_s)), grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request Instantaneous Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## LOCAL CONFIG\n",
    "# Minimum time (in seconds)\n",
    "MIN_TIME = None\n",
    "# Maximum time (in seconds)\n",
    "MAX_TIME = None\n",
    "\n",
    "fig = plt.figure(figsize=(24, 12))\n",
    "df = requests[requests[\"status\"] == \"successful\"]\n",
    "if MIN_TIME:\n",
    "    df = df[(df.index >= MIN_TIME)]\n",
    "if MAX_TIME:\n",
    "    df = df[(df.index <= MAX_TIME)]\n",
    "ax = fig.gca()\n",
    "ax.grid(alpha=0.75)\n",
    "ax.set_xlim((int(df.index.min()), int(df.index.max())))\n",
    "ax.set_ylim((0, max_latency_in_s))\n",
    "ax.axvline(x=RAMP_UP_DURATION, ls=\"--\", color=\"green\")\n",
    "ax.axvline(x=requests.index.values.max() - RAMP_DOWN_DURATION, ls=\"--\", color=\"green\")\n",
    "df[\"latency\"].plot(ax=ax, kind=\"line\", title=\"Latency of Successful Requests\", xlabel=\"Time (seconds)\",\n",
    "        ylabel=\"Latency (seconds)\", color=\"purple\", grid=True,\n",
    "        xticks=range(int(df.index.min()), int(df.index.max()) + 1, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## LOCAL CONFIG\n",
    "# Minimum time (in seconds)\n",
    "MIN_TIME = None\n",
    "# Maximum time (in seconds)\n",
    "MAX_TIME = None\n",
    "\n",
    "fig = plt.figure(figsize=(24, n_request_types * 12))\n",
    "for (i, request_type) in enumerate(requests.type.unique()):\n",
    "  df = requests[(requests[\"status\"] == \"successful\") & (requests[\"type\"] == request_type)]\n",
    "  if MIN_TIME:\n",
    "    df = df[(df.index >= MIN_TIME)]\n",
    "  if MAX_TIME:\n",
    "    df = df[(df.index <= MAX_TIME)]\n",
    "  ax = fig.add_subplot(n_request_types, 1, i + 1)\n",
    "  ax.grid(alpha=0.75)\n",
    "  ax.set_xlim((int(df.index.min()), int(df.index.max())))\n",
    "  ax.set_ylim((0, max_latency_in_s))\n",
    "  ax.axvline(x=RAMP_UP_DURATION, ls=\"--\", color=\"green\")\n",
    "  ax.axvline(x=requests.index.values.max() - RAMP_DOWN_DURATION, ls=\"--\", color=\"green\")\n",
    "  df[\"latency\"].plot(ax=ax, kind=\"line\", title=request_type, xlabel=\"Time (seconds)\",\n",
    "      ylabel=\"Latency (seconds)\", color=\"purple\", grid=True,\n",
    "      xticks=range(int(df.index.min()), int(df.index.max()) + 1, 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request Throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24, 12))\n",
    "ax = fig.gca()\n",
    "ax.grid(alpha=0.75)\n",
    "ax.axvline(x=RAMP_UP_DURATION, ls=\"--\", color=\"green\")\n",
    "ax.axvline(x=requests.index.values.max() - RAMP_DOWN_DURATION, ls=\"--\", color=\"green\")\n",
    "df = requests.groupby([\"window_1000\", \"status\"])[\"window_1000\"].count().unstack().fillna(0)\n",
    "df = df.reindex(range(0, int(df.index.max()) + 1), fill_value=0)\n",
    "ax.set_xlim((int(df.index.min()), int(df.index.max())))\n",
    "df.plot(ax=ax, kind=\"line\", title=\"Throughput (requests per second)\", xlabel=\"Time (seconds)\",\n",
    "        ylabel=\"Requests (count)\", color={\"failed\": \"red\", \"successful\": \"blue\"}, legend=True, grid=True,\n",
    "        xticks=range(0, int(df.index.max()) + 1, 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of requests\")\n",
    "print(\"  Total:       %7d\" % requests.shape[0])\n",
    "print(\"  Status\")\n",
    "print(\"    Failed:    %7d (%9.5f%%)\" % (requests[requests[\"status\"] == \"failed\"][\"status\"].count(),\n",
    "    (requests[requests[\"status\"] == \"failed\"][\"status\"].count() / requests.shape[0]) * 100))\n",
    "print(\"    Succesful: %7d (%9.5f%%)\" % (requests[requests[\"status\"] == \"successful\"][\"status\"].count(),\n",
    "    (requests[requests[\"status\"] == \"successful\"][\"status\"].count() / requests.shape[0]) * 100))\n",
    "print(\"  Type\")\n",
    "print(\"    Read:      %7d (%9.5f%%)\" % (requests[requests[\"rw\"] == \"read\"][\"rw\"].count(),\n",
    "    (requests[requests[\"rw\"] == \"read\"][\"rw\"].count() / requests.shape[0]) * 100))\n",
    "print(\"    Write:     %7d (%9.5f%%)\" % (requests[requests[\"rw\"] == \"write\"][\"rw\"].count(),\n",
    "    (requests[requests[\"rw\"] == \"write\"][\"rw\"].count() / requests.shape[0]) * 100))\n",
    "print(\"Experiment duration (s)\")\n",
    "print(\"  Total:       %7.3f\" % (requests.index.values.max() - requests.index.values.min()))\n",
    "print(\"Latency (ms)\")\n",
    "print(\"P99.9:         %7.2f\" % (requests[requests[\"status\"] == \"successful\"][\"latency\"].quantile(0.999) * 1000))\n",
    "print(\"  P99:         %7.2f\" % (requests[requests[\"status\"] == \"successful\"][\"latency\"].quantile(0.99) * 1000))\n",
    "print(\"  P95:         %7.2f\" % (requests[requests[\"status\"] == \"successful\"][\"latency\"].quantile(0.95) * 1000))\n",
    "print(\"  P50:         %7.2f\" % (requests[requests[\"status\"] == \"successful\"][\"latency\"].quantile(0.50) * 1000))\n",
    "print(\"  Avg:         %7.2f\" % (requests[requests[\"status\"] == \"successful\"][\"latency\"].mean() * 1000))\n",
    "print(\"  Std:         %7.2f\" % (requests[requests[\"status\"] == \"successful\"][\"latency\"].std() * 1000))\n",
    "print(\"Throughput (req/s)\")\n",
    "print(\"  P99:         %7.2f\" % requests.groupby([\"window_1000\"])[\"window_1000\"].count().reindex(range(int(requests[\"window_1000\"].min()), int(requests[\"window_1000\"].max()) + 1), fill_value=0).quantile(0.99))\n",
    "print(\"  P95:         %7.2f\" % requests.groupby([\"window_1000\"])[\"window_1000\"].count().reindex(range(int(requests[\"window_1000\"].min()), int(requests[\"window_1000\"].max()) + 1), fill_value=0).quantile(0.95))\n",
    "print(\"  P50:         %7.2f\" % requests.groupby([\"window_1000\"])[\"window_1000\"].count().reindex(range(int(requests[\"window_1000\"].min()), int(requests[\"window_1000\"].max()) + 1), fill_value=0).quantile(0.50))\n",
    "print(\"  Avg:         %7.2f\" % requests.groupby([\"window_1000\"])[\"window_1000\"].count().reindex(range(int(requests[\"window_1000\"].min()), int(requests[\"window_1000\"].max()) + 1), fill_value=0).mean())\n",
    "print(\"  Std:         %7.2f\" % requests.groupby([\"window_1000\"])[\"window_1000\"].count().reindex(range(int(requests[\"window_1000\"].min()), int(requests[\"window_1000\"].max()) + 1), fill_value=0).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = requests[(requests.index >= RAMP_UP_DURATION) & (requests.index <= requests.index.max() - RAMP_DOWN_DURATION)]\n",
    "print(\"Number of requests (Excluding Ramping Up and Down Periods)\")\n",
    "print(\"  Total:       %7d\" % df.shape[0])\n",
    "print(\"  Status\")\n",
    "print(\"    Failed:    %7d (%9.5f%%)\" % (df[df[\"status\"] == \"failed\"][\"status\"].count(),\n",
    "    (df[df[\"status\"] == \"failed\"][\"status\"].count() / df.shape[0]) * 100))\n",
    "print(\"    Succesful: %7d (%9.5f%%)\" % (df[df[\"status\"] == \"successful\"][\"status\"].count(),\n",
    "    (df[df[\"status\"] == \"successful\"][\"status\"].count() / df.shape[0]) * 100))\n",
    "print(\"  Type\")\n",
    "print(\"    Read:      %7d (%9.5f%%)\" % (df[df[\"rw\"] == \"read\"][\"rw\"].count(),\n",
    "    (df[df[\"rw\"] == \"read\"][\"rw\"].count() / df.shape[0]) * 100))\n",
    "print(\"    Write:     %7d (%9.5f%%)\" % (df[df[\"rw\"] == \"write\"][\"rw\"].count(),\n",
    "    (df[df[\"rw\"] == \"write\"][\"rw\"].count() / df.shape[0]) * 100))\n",
    "print(\"Experiment duration (s)\")\n",
    "print(\"  Total:       %7.3f\" % (df.index.values.max() - df.index.values.min()))\n",
    "print(\"Latency (ms)\")\n",
    "print(\"P99.9:         %7.2f\" % (df[df[\"status\"] == \"successful\"][\"latency\"].quantile(0.999) * 1000))\n",
    "print(\"  P99:         %7.2f\" % (df[df[\"status\"] == \"successful\"][\"latency\"].quantile(0.99) * 1000))\n",
    "print(\"  P95:         %7.2f\" % (df[df[\"status\"] == \"successful\"][\"latency\"].quantile(0.95) * 1000))\n",
    "print(\"  P50:         %7.2f\" % (df[df[\"status\"] == \"successful\"][\"latency\"].quantile(0.50) * 1000))\n",
    "print(\"  Avg:         %7.2f\" % (df[df[\"status\"] == \"successful\"][\"latency\"].mean() * 1000))\n",
    "print(\"  Std:         %7.2f\" % (df[df[\"status\"] == \"successful\"][\"latency\"].std() * 1000))\n",
    "print(\"Throughput (req/s)\")\n",
    "print(\"  P99:         %7.2f\" % df.groupby([\"window_1000\"])[\"window_1000\"].count().reindex(range(int(df[\"window_1000\"].min()), int(df[\"window_1000\"].max()) + 1), fill_value=0).quantile(0.99))\n",
    "print(\"  P95:         %7.2f\" % df.groupby([\"window_1000\"])[\"window_1000\"].count().reindex(range(int(df[\"window_1000\"].min()), int(df[\"window_1000\"].max()) + 1), fill_value=0).quantile(0.95))\n",
    "print(\"  P50:         %7.2f\" % df.groupby([\"window_1000\"])[\"window_1000\"].count().reindex(range(int(df[\"window_1000\"].min()), int(df[\"window_1000\"].max()) + 1), fill_value=0).quantile(0.50))\n",
    "print(\"  Avg:         %7.2f\" % df.groupby([\"window_1000\"])[\"window_1000\"].count().reindex(range(int(df[\"window_1000\"].min()), int(df[\"window_1000\"].max()) + 1), fill_value=0).mean())\n",
    "print(\"  Std:         %7.2f\" % df.groupby([\"window_1000\"])[\"window_1000\"].count().reindex(range(int(df[\"window_1000\"].min()), int(df[\"window_1000\"].max()) + 1), fill_value=0).std())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
