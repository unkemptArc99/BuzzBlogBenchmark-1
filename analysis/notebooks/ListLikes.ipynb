{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\")))\n",
    "from utils.utils import *\n",
    "\n",
    "class Experiment:\n",
    "\n",
    "    EXPERIMENT_DIRNAME = None\n",
    "    RAMP_UP_DURATION = None\n",
    "    RAMP_DOWN_DURATION = None\n",
    "\n",
    "    OUTPUT_DIRECTORY = None\n",
    "\n",
    "    LOADGEN_CPU_CORES = 20\n",
    "    APIGATEWAY_CPU_CORES = 20\n",
    "    MICROSERVICE_CPU_CORES = 2\n",
    "    DATABASE_CPU_CORES = 2\n",
    "    REDIS_CPU_CORES = 2\n",
    "    # Analyzed metric (options: \"user\", \"nice\", \"system\", \"wait\", \"irq\", \"soft\",\n",
    "    # \"steal\", \"idle\", \"total\", \"guest\", \"guest_n\", \"intrpt\")\n",
    "    COLLECTL_CPU_METRIC = \"total\"\n",
    "    # Filter CPU cores\n",
    "    COLLECTL_CPU_CORES = {\n",
    "        \"node-0\": range(LOADGEN_CPU_CORES), \"node-1\": range(LOADGEN_CPU_CORES), \"node-2\": range(LOADGEN_CPU_CORES), \"node-3\": range(LOADGEN_CPU_CORES),\n",
    "        \"node-4\": range(APIGATEWAY_CPU_CORES), \"node-5\": range(APIGATEWAY_CPU_CORES), \"node-6\": range(APIGATEWAY_CPU_CORES), \"node-7\": range(APIGATEWAY_CPU_CORES),\n",
    "        \"node-8\": range(MICROSERVICE_CPU_CORES),\n",
    "        \"node-9\": range(DATABASE_CPU_CORES),\n",
    "        \"node-10\": range(MICROSERVICE_CPU_CORES),\n",
    "        \"node-11\": range(MICROSERVICE_CPU_CORES),\n",
    "        \"node-12\": range(MICROSERVICE_CPU_CORES),\n",
    "        \"node-13\": range(DATABASE_CPU_CORES),\n",
    "        \"node-14\": range(MICROSERVICE_CPU_CORES),\n",
    "        \"node-15\": range(DATABASE_CPU_CORES),\n",
    "        \"node-16\": range(MICROSERVICE_CPU_CORES),\n",
    "        \"node-17\": range(REDIS_CPU_CORES),\n",
    "        \"node-18\": range(MICROSERVICE_CPU_CORES),\n",
    "    }\n",
    "\n",
    "    experiment_dirpath = None\n",
    "    output_dirpath = None\n",
    "    loadgen_requests = None\n",
    "    rpc_requests = None\n",
    "    function_names = None\n",
    "    functions_of_interest = ['account:retrieve_standard_account',\n",
    "                             'like:count_likes_of_post',\n",
    "                             'like:list_likes',\n",
    "                             'post:retrieve_expanded_post',\n",
    "                             'uniquepair:count',\n",
    "                             'uniquepair:fetch']\n",
    "    bl = None\n",
    "    node_names = None\n",
    "    nodes_of_interest = ['node-8',\n",
    "                        'node-9',\n",
    "                        'node-11',\n",
    "                        'node-12',\n",
    "                        'node-13',\n",
    "                        'node-14',\n",
    "                        'node-15']\n",
    "    cpu = None\n",
    "    start_time = None\n",
    "    max_latency_in_s = None\n",
    "    n_request_types = None\n",
    "\n",
    "    successful_requests_num = None\n",
    "    failed_requests_num = None\n",
    "\n",
    "    read_requests = None\n",
    "    write_requests = None\n",
    "\n",
    "    df = None\n",
    "\n",
    "    def __init__(self, ex_dir, ru, rd, out_dir):\n",
    "        self.EXPERIMENT_DIRNAME = ex_dir\n",
    "        self.RAMP_UP_DURATION = int(ru)\n",
    "        self.RAMP_DOWN_DURATION = int(rd)\n",
    "        self.OUTPUT_DIRECTORY = out_dir\n",
    "        self.experiment_dirpath = os.path.join(os.path.abspath(\"\"), \"..\", \"data\", \\\n",
    "                                                self.EXPERIMENT_DIRNAME)\n",
    "        self.output_dirpath = os.path.join(os.path.abspath(\"\"), \"..\", \"data\", \\\n",
    "                                                self.OUTPUT_DIRECTORY)\n",
    "\n",
    "    def cache_request(self):\n",
    "        print(\"Loadgen Request Caching Start...\")\n",
    "        # self.loadgen_requests = pd.concat([df[2] for df in get_loadgen_df(self.experiment_dirpath)])\n",
    "        # self.start_time = get_experiment_start_time(self.experiment_dirpath)\n",
    "        # self.max_latency_in_s = int(self.loadgen_requests[\"latency\"].max()) + 1.0\n",
    "        # self.n_request_types = len(self.loadgen_requests.type.unique())\n",
    "        # self.loadgen_requests[\"timestamp\"] = self.loadgen_requests.apply(\n",
    "        #     lambda r: (r[\"timestamp\"] - self.start_time).total_seconds(), axis=1)\n",
    "        # self.loadgen_requests[\"window_1000\"] = self.loadgen_requests[\"timestamp\"].\\\n",
    "        #     round(0).multiply(1000)\n",
    "        # self.loadgen_requests[\"window_10\"] = self.loadgen_requests[\"timestamp\"].\\\n",
    "        #     round(2).multiply(1000)\n",
    "        # self.loadgen_requests.set_index(\"timestamp\", inplace=True)\n",
    "        # self.loadgen_requests.sort_index(inplace=True)\n",
    "        print(\"Loadgen Request Cache Complete.\")\n",
    "\n",
    "        print(\"RPC Request Caching Start...\")\n",
    "        # self.rpc_requests = pd.concat([df[2] for df in get_rpc_df(self.experiment_dirpath)])\n",
    "        # self.function_names = sorted(self.rpc_requests[\"function\"].unique())\n",
    "        # self.rpc_requests[\"timestamp\"] = self.rpc_requests.apply(lambda r: (r[\"timestamp\"] - self.start_time).total_seconds(), axis=1)\n",
    "        # self.rpc_requests[\"latency\"] = self.rpc_requests[\"latency\"].multiply(1000)\n",
    "        # self.rpc_requests[\"window_1000\"] = self.rpc_requests[\"timestamp\"].round(0).multiply(1000)\n",
    "        # self.rpc_requests[\"window_10\"] = self.rpc_requests[\"timestamp\"].round(2).multiply(1000)\n",
    "        # self.rpc_requests.set_index(\"timestamp\", inplace=True)\n",
    "        # self.rpc_requests.sort_index(inplace=True)\n",
    "        print(\"RPC Request Cache Complete.\")\n",
    "\n",
    "        print(\"TCP Backlog Cache Start...\")\n",
    "        strt_t = get_experiment_start_time(self.experiment_dirpath) - pd.Timedelta(hours=6)\n",
    "        self.bl =  pd.concat([df[2] for df in get_tcplistenbl_df(self.experiment_dirpath)])\n",
    "        self.node_names = get_node_names(self.experiment_dirpath)\n",
    "        self.bl[\"timestamp\"] = self.bl.apply(lambda r: (r[\"timestamp\"] - strt_t).total_seconds(), axis=1)\n",
    "        self.bl[\"window_1000\"] = self.bl[\"timestamp\"].round(0).multiply(1000)\n",
    "        self.bl[\"window_10\"] = self.bl[\"timestamp\"].round(2).multiply(1000)\n",
    "        self.bl.set_index(\"timestamp\", inplace=True)\n",
    "        self.bl.sort_index(inplace=True)\n",
    "        print(\"TCP Backlog Cache Complete.\")\n",
    "\n",
    "        print(\"CPU Collectl Caching Start...\")\n",
    "        # self.cpu = pd.concat([df[2] for df in get_collectl_cpu_df(self.experiment_dirpath)])\n",
    "        # self.cpu[\"timestamp\"] = self.cpu.apply(lambda r: (r[\"timestamp\"] - self.start_time).total_seconds(), axis=1)\n",
    "        # self.cpu[\"window_1000\"] = self.cpu[\"timestamp\"].round(0).multiply(1000)\n",
    "        # self.cpu.set_index(\"timestamp\", inplace=True)\n",
    "        # self.cpu.sort_index(inplace=True)\n",
    "        print(\"CPU Collectl Caching Complete.\")\n",
    "\n",
    "\n",
    "    def success_fail_metric(self):\n",
    "        self.df = self.loadgen_requests[(self.loadgen_requests.index >= self.RAMP_UP_DURATION)]\n",
    "        self.df = self.loadgen_requests[(self.loadgen_requests.index <= \\\n",
    "            self.loadgen_requests.index.max() - self.RAMP_DOWN_DURATION)]\n",
    "        df_temp = self.df.groupby([\"status\"]).count()[\"method\"]\n",
    "        self.successful_requests_num = df_temp['successful']\n",
    "        self.failed_requests_num = df_temp['failed']\n",
    "        with open(os.path.join(self.output_dirpath, 'stats.txt'), 'a') as f:\n",
    "            f.write('Requests Success/Fail Metrics\\n')\n",
    "            f.write('-----------------------------\\n')\n",
    "            f.write('Successful Requests: ' + str(self.successful_requests_num) + '\\n')\n",
    "            f.write('Failed Requests: ' + str(self.failed_requests_num) + '\\n')\n",
    "            f.write('\\n')\n",
    "\n",
    "    def rw_metric(self):\n",
    "        df_temp = self.df.groupby([\"rw\"]).count()[\"method\"]\n",
    "        self.read_requests = df_temp['read']\n",
    "        self.write_requests = df_temp['write']\n",
    "        with open(os.path.join(self.output_dirpath, 'stats.txt'), 'a') as f:\n",
    "            f.write('Read/Write Metrics\\n')\n",
    "            f.write('------------------\\n')\n",
    "            f.write('Read Requests: ' + str(self.read_requests) + '\\n')\n",
    "            f.write('Write Requests: ' + str(self.write_requests) + '\\n')\n",
    "            f.write('\\n')\n",
    "\n",
    "    def lat_distr(self):\n",
    "        LATENCY_BIN_IN_MS = 200\n",
    "        # Data frame\n",
    "        df = self.df[(self.df[\"status\"] == \"successful\")]\n",
    "        df[\"latency_bin\"] = df.apply(\n",
    "            lambda r: int(r[\"latency\"] * 1000 // LATENCY_BIN_IN_MS), axis=1)\n",
    "        p999 = df[\"latency\"].quantile(0.999) * 1000\n",
    "        p50 = df[\"latency\"].quantile(0.50) * 1000\n",
    "        # Plot\n",
    "        fig = plt.figure(figsize=(24, 12))\n",
    "        ax = fig.gca(xlabel=\"Latency (millisec)\", ylabel=\"Requests (count)\")\n",
    "        ax.grid(alpha=0.75)\n",
    "        ax.set_yscale(\"log\")\n",
    "        ax.set_xlim((0, (1000 // LATENCY_BIN_IN_MS) * self.max_latency_in_s))\n",
    "        ax.set_xticks(range(int((1000 // LATENCY_BIN_IN_MS) * self.max_latency_in_s) + 1))\n",
    "        ax.set_xticklabels(\n",
    "            range(0, \\\n",
    "                (int((1000 // LATENCY_BIN_IN_MS) * self.max_latency_in_s) \\\n",
    "                    + 1) * LATENCY_BIN_IN_MS, LATENCY_BIN_IN_MS))\n",
    "        ax.axvline(x=p50 / LATENCY_BIN_IN_MS, ls=\"dotted\", lw=5, color=\"darkorange\")\n",
    "        ax.text(x=p50 / LATENCY_BIN_IN_MS, y=1000, s=\" P50\", fontsize=22, color=\"darkorange\")\n",
    "        ax.axvline(x=p999 / LATENCY_BIN_IN_MS, ls=\"dotted\", lw=5, color=\"darkorange\")\n",
    "        ax.text(x=p999 / LATENCY_BIN_IN_MS, y=100, s=\" P99.9\", fontsize=22, color=\"darkorange\")\n",
    "        df[\"latency_bin\"].plot(ax=ax, kind=\"hist\", \\\n",
    "            title=\"Latency Distribution of Successful Requests Excluding Ramping Periods\", \\\n",
    "                bins=range(int((1000 // LATENCY_BIN_IN_MS) * self.max_latency_in_s)), grid=True)\n",
    "        fig.savefig(os.path.join(self.output_dirpath, 'latdist.png'))\n",
    "        plt.close()\n",
    "\n",
    "    def pit_graph(self):\n",
    "        # Data frame\n",
    "        df = self.loadgen_requests[self.loadgen_requests[\"status\"] == \"successful\"]\n",
    "        df = df.groupby([\"window_1000\"])[\"latency\"].max().reindex(\n",
    "            range(0, int(df[\"window_1000\"].max()) + 1, 1000), fill_value=0)\n",
    "        # Plot\n",
    "        fig = plt.figure(figsize=(24, 12))\n",
    "        ax = fig.gca()\n",
    "        ax.grid(alpha=0.75)\n",
    "        ax.set_xlim((int(df.index.min()), int(df.index.max())))\n",
    "        ax.set_ylim((0, self.max_latency_in_s))\n",
    "        ax.axvline(x=self.RAMP_UP_DURATION * 1000, ls=\"--\", color=\"green\")\n",
    "        ax.axvline(x=df.index.max() - (self.RAMP_DOWN_DURATION * 1000), ls=\"--\", color=\"green\")\n",
    "        df.plot(\n",
    "            ax=ax,\n",
    "            kind=\"line\",\n",
    "            title=\"Latency of Successful Requests\",\n",
    "            xlabel=\"Time (millisec)\",\n",
    "            ylabel=\"Latency (sec)\",\n",
    "            color=\"purple\",\n",
    "            grid=True,\n",
    "            xticks=range(int(df.index.min()), int(df.index.max()) + 1, 60000)\n",
    "            )\n",
    "        fig.savefig(os.path.join(self.output_dirpath, 'pit_graph.png'))\n",
    "        plt.close()\n",
    "\n",
    "    def thput_graph(self):\n",
    "        # Data frame\n",
    "        df = self.loadgen_requests.groupby([\"window_1000\", \"status\"])[\"window_1000\"].count().unstack().fillna(0)\n",
    "        df = df.reindex(range(0, int(df.index.max()) + 1, 1000), fill_value=0)\n",
    "        # Plot\n",
    "        fig = plt.figure(figsize=(24, 12))\n",
    "        ax = fig.gca()\n",
    "        ax.grid(alpha=0.75)\n",
    "        ax.axvline(x=self.RAMP_UP_DURATION * 1000, ls=\"--\", color=\"green\")\n",
    "        ax.axvline(x=self.loadgen_requests.index.values.max() - (self.RAMP_DOWN_DURATION * 1000), ls=\"--\", color=\"green\")\n",
    "        ax.set_xlim((int(df.index.min()), int(df.index.max())))\n",
    "        df.plot(\n",
    "            ax=ax,\n",
    "            kind=\"line\",\n",
    "            title=\"Throughput (requests per second)\",\n",
    "            xlabel=\"Time (millisec)\",\n",
    "            ylabel=\"Requests (count)\",\n",
    "            color={\"failed\": \"red\", \"successful\": \"blue\"},\n",
    "            legend=True,\n",
    "            grid=True,\n",
    "            xticks=range(int(df.index.min()), int(df.index.max()) + 1, 60000)\n",
    "            )\n",
    "        fig.savefig(os.path.join(self.output_dirpath, 'thput_graph.png'))\n",
    "        plt.close()\n",
    "\n",
    "    def print_summary(self):\n",
    "        df = self.loadgen_requests[(self.loadgen_requests.index >= self.RAMP_UP_DURATION) & (self.loadgen_requests.index <= self.loadgen_requests.index.max() - self.RAMP_DOWN_DURATION)]\n",
    "        with open(os.path.join(self.output_dirpath, 'stats.txt'), 'a') as f:\n",
    "            f.write(\"Summary\\n\")\n",
    "            f.write(\"-------\\n\")\n",
    "            f.write(\"Number of requests (Excluding Ramping Up and Down Periods)\\n\")\n",
    "            f.write(\"  Total:       %7d\\n\" % df.shape[0])\n",
    "            f.write(\"  Status\\n\")\n",
    "            f.write(\"    Failed:    %7d (%9.5f%%)\\n\" % (df[df[\"status\"] == \"failed\"][\"status\"].count(),\n",
    "                (df[df[\"status\"] == \"failed\"][\"status\"].count() / df.shape[0]) * 100))\n",
    "            f.write(\"    Succesful: %7d (%9.5f%%)\\n\" % (df[df[\"status\"] == \"successful\"][\"status\"].count(),\n",
    "                (df[df[\"status\"] == \"successful\"][\"status\"].count() / df.shape[0]) * 100))\n",
    "            f.write(\"  Type\")\n",
    "            f.write(\"    Read:      %7d (%9.5f%%)\\n\" % (df[df[\"rw\"] == \"read\"][\"rw\"].count(),\n",
    "                (df[df[\"rw\"] == \"read\"][\"rw\"].count() / df.shape[0]) * 100))\n",
    "            f.write(\"    Write:     %7d (%9.5f%%)\\n\" % (df[df[\"rw\"] == \"write\"][\"rw\"].count(),\n",
    "                (df[df[\"rw\"] == \"write\"][\"rw\"].count() / df.shape[0]) * 100))\n",
    "            f.write(\"Experiment duration (s)\\n\")\n",
    "            f.write(\"  Total:       %7.3f\" % (df.index.values.max() - df.index.values.min()))\n",
    "            f.write(\"Latency (ms)\\n\")\n",
    "            f.write(\"P99.9:         %7.2f\\n\" % (df[df[\"status\"] == \"successful\"][\"latency\"].quantile(0.999) * 1000))\n",
    "            f.write(\"  P99:         %7.2f\\n\" % (df[df[\"status\"] == \"successful\"][\"latency\"].quantile(0.99) * 1000))\n",
    "            f.write(\"  P95:         %7.2f\\n\" % (df[df[\"status\"] == \"successful\"][\"latency\"].quantile(0.95) * 1000))\n",
    "            f.write(\"  P50:         %7.2f\\n\" % (df[df[\"status\"] == \"successful\"][\"latency\"].quantile(0.50) * 1000))\n",
    "            f.write(\"  Avg:         %7.2f\\n\" % (df[df[\"status\"] == \"successful\"][\"latency\"].mean() * 1000))\n",
    "            f.write(\"  Std:         %7.2f\\n\" % (df[df[\"status\"] == \"successful\"][\"latency\"].std() * 1000))\n",
    "            f.write(\"Throughput (req/s)\\n\")\n",
    "            f.write(\"  P99:         %7.2f\\n\" % df.groupby([\"window_1000\"])[\"window_1000\"].count().reindex(range(int(df[\"window_1000\"].min()), int(df[\"window_1000\"].max()) + 1, 1000), fill_value=0).quantile(0.99))\n",
    "            f.write(\"  P95:         %7.2f\\n\" % df.groupby([\"window_1000\"])[\"window_1000\"].count().reindex(range(int(df[\"window_1000\"].min()), int(df[\"window_1000\"].max()) + 1, 1000), fill_value=0).quantile(0.95))\n",
    "            f.write(\"  P50:         %7.2f\\n\" % df.groupby([\"window_1000\"])[\"window_1000\"].count().reindex(range(int(df[\"window_1000\"].min()), int(df[\"window_1000\"].max()) + 1, 1000), fill_value=0).quantile(0.50))\n",
    "            f.write(\"  Avg:         %7.2f\\n\" % df.groupby([\"window_1000\"])[\"window_1000\"].count().reindex(range(int(df[\"window_1000\"].min()), int(df[\"window_1000\"].max()) + 1, 1000), fill_value=0).mean())\n",
    "            f.write(\"  Std:         %7.2f\\n\" % df.groupby([\"window_1000\"])[\"window_1000\"].count().reindex(range(int(df[\"window_1000\"].min()), int(df[\"window_1000\"].max()) + 1, 1000), fill_value=0).std())\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    def rpc(self):\n",
    "        self.rpc_lat_distr()\n",
    "        self.rpc_pit_graph()\n",
    "        self.rpc_stats()\n",
    "\n",
    "    def rpc_lat_distr(self):\n",
    "        LATENCY_BIN_IN_MS = 200\n",
    "        for (i, function) in enumerate(self.functions_of_interest):\n",
    "            # Data frame\n",
    "            fig = plt.figure(figsize=(24,12))\n",
    "            df = self.rpc_requests[(self.rpc_requests[\"function\"] == function)]\n",
    "            if df.empty:\n",
    "                continue\n",
    "            df[\"latency_bin\"] = df.apply(lambda r: int(r[\"latency\"] // LATENCY_BIN_IN_MS), axis=1)\n",
    "            p999 = df[\"latency\"].quantile(0.999)\n",
    "            p50 = df[\"latency\"].quantile(0.50)\n",
    "            # Plot\n",
    "            ax = fig.add_subplot(1, 1, 1)\n",
    "            ax.set_yscale(\"log\")\n",
    "            ax.grid(alpha=0.75)\n",
    "            ax.set_xlim((0, (1000 // LATENCY_BIN_IN_MS) * self.max_latency_in_s))\n",
    "            ax.set_xticks(range(int((1000 // LATENCY_BIN_IN_MS) * self.max_latency_in_s) + 1))\n",
    "            ax.set_xticklabels(\n",
    "                range(\n",
    "                    0,\n",
    "                    (int((1000 // LATENCY_BIN_IN_MS) * self.max_latency_in_s) + 1) * LATENCY_BIN_IN_MS,\n",
    "                    LATENCY_BIN_IN_MS\n",
    "                    )\n",
    "                )\n",
    "            ax.axvline(x=p50 / LATENCY_BIN_IN_MS, ls=\"dotted\", lw=5, color=\"darkorange\")\n",
    "            ax.text(x=p50 / LATENCY_BIN_IN_MS, y=10, s=\" P50\", fontsize=22, color=\"darkorange\")\n",
    "            ax.axvline(x=p999 / LATENCY_BIN_IN_MS, ls=\"dotted\", lw=5, color=\"darkorange\")\n",
    "            ax.text(x=p999 / LATENCY_BIN_IN_MS, y=10, s=\" P99.9\", fontsize=22, color=\"darkorange\")\n",
    "            df[\"latency_bin\"].plot(\n",
    "                ax=ax,\n",
    "                kind=\"hist\",\n",
    "                title=\"Latency Distribution - %s\" % function,\n",
    "                xlabel=\"Latency (milliseconds)\",\n",
    "                ylabel=\"Calls (count)\",\n",
    "                bins=range((1000 // LATENCY_BIN_IN_MS) * int(self.max_latency_in_s)),\n",
    "                grid=True\n",
    "                )\n",
    "            plt.subplots_adjust(hspace=0.25)\n",
    "            fig.savefig(os.path.join(self.output_dirpath, 'rpc', 'latency_distribution', 'rpc_lat_dist_' + function +'.png'))\n",
    "            plt.close()\n",
    "\n",
    "    def rpc_pit_graph(self):\n",
    "        for (i, function) in enumerate(self.functions_of_interest):\n",
    "            # Data frame\n",
    "            fig = plt.figure(figsize=(24,12))\n",
    "            df = self.rpc_requests[(self.rpc_requests[\"function\"] == function)].groupby([\"window_1000\"])[\"latency\"].max().reindex(\n",
    "                range(0, int(self.rpc_requests[\"window_1000\"].max()) + 1, 1000), fill_value=0)\n",
    "            # Plot\n",
    "            ax = fig.add_subplot(1, 1, 1)\n",
    "            ax.grid(alpha=0.75)\n",
    "            ax.set_xlim((0, int(df.index.max())))\n",
    "            ax.set_ylim((0, df.values.max()))\n",
    "            df.plot(\n",
    "                ax=ax,\n",
    "                kind=\"line\",\n",
    "                title=\"Instantaneous Latency - %s\" % function,\n",
    "                xlabel=\"Time (millisec)\",\n",
    "                ylabel=\"Latency (millisec)\",\n",
    "                grid=True\n",
    "                )\n",
    "            plt.subplots_adjust(hspace=0.25)\n",
    "            fig.savefig(os.path.join(self.output_dirpath, 'rpc', 'pit', 'rpc_pit_' + function +'.png'))\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "    def server_queue(self):\n",
    "        for (i, node_name) in enumerate(self.nodes_of_interest):\n",
    "            fig = plt.figure(figsize=(24, 12))\n",
    "            # Data frame\n",
    "            df = self.bl[(self.bl[\"node_name\"] == node_name)].groupby([\"window_1000\"])[\"len\"].max().reindex(range(0, int(self.bl[\"window_1000\"].max()) + 1, 1000), fill_value=0)\n",
    "            # Plot\n",
    "            if df.empty:\n",
    "                print(node_name)\n",
    "                continue\n",
    "            ax = fig.add_subplot(1, 1, 1)\n",
    "            ax.set_xlim((0, df.index.max()))\n",
    "            ax.set_ylim((0, df.values.max()))\n",
    "            ax.grid(alpha=0.75)\n",
    "            df.plot(\n",
    "                ax=ax, \n",
    "                kind=\"line\", \n",
    "                title=\"%s - Queue Length\" % node_name, \n",
    "                xlabel=\"Time (millisec)\", \n",
    "                ylabel=\"Requests (count)\", \n",
    "                grid=True, \n",
    "                legend=False\n",
    "                )\n",
    "            fig.savefig(os.path.join(self.output_dirpath, 'queue', 'server_queue_' + node_name +'.png'))\n",
    "            plt.close()\n",
    "\n",
    "    def server_cpu(self):\n",
    "        for (i, node_name) in enumerate(self.nodes_of_interest):\n",
    "            fig = plt.figure(figsize=(24, 12))\n",
    "            # Data frame\n",
    "            df = self.cpu[(self.cpu[\"node_name\"] == node_name) & (self.cpu[\"hw_no\"].isin(self.COLLECTL_CPU_CORES[node_name]))].groupby([\"window_1000\"])[self.COLLECTL_CPU_METRIC].mean()\n",
    "            # Plot\n",
    "            ax = fig.add_subplot(1, 1, 1)\n",
    "            ax.set_xlim((0, df.index.max()))\n",
    "            ax.set_ylim((0, 100))\n",
    "            ax.grid(alpha=0.75)\n",
    "            df.plot(ax=ax, kind=\"line\", title=\"%s - CPU Utilization\" % node_name, xlabel=\"Time (millisec)\", ylabel=\"%s (%%)\" % self.COLLECTL_CPU_METRIC, grid=True, legend=False, yticks=range(0, 101, 10))\n",
    "            fig.savefig(os.path.join(self.output_dirpath, 'cpu', 'server_cpu_' + node_name +'.png'))\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "    def rpc_stats(self):\n",
    "        for (i, function) in enumerate(self.functions_of_interest):\n",
    "            df = self.rpc_requests[(self.rpc_requests[\"function\"] == function)]\n",
    "            with open(os.path.join(self.output_dirpath, 'stats.txt'), 'a') as f:\n",
    "                f.write('RPC Summary\\n')\n",
    "                f.write('-----------\\n')\n",
    "                f.write(function)\n",
    "                f.write(\"  Number of RPCs/s\\n\")\n",
    "                f.write(\"    Total:       %7d\\n\" % df.shape[0])\n",
    "                f.write(\"    Avg:         %7.2f\\n\" % (df.shape[0] / (df.index.max() - df.index.min())))\n",
    "                f.write(\"  Latency (ms)\\n\")\n",
    "                f.write(\" P99.99:         %7.2f\\n\" % (df[\"latency\"].quantile(0.9999)))\n",
    "                f.write(\"  P99.9:         %7.2f\\n\" % (df[\"latency\"].quantile(0.999)))\n",
    "                f.write(\"    P99:         %7.2f\\n\" % (df[\"latency\"].quantile(0.99)))\n",
    "                f.write(\"    P95:         %7.2f\\n\" % (df[\"latency\"].quantile(0.95)))\n",
    "                f.write(\"    P50:         %7.2f\\n\" % (df[\"latency\"].quantile(0.50)))\n",
    "                f.write(\"    Avg:         %7.2f\\n\" % (df[\"latency\"].mean()))\n",
    "                f.write(\"    Std:         %7.2f\\n\" % (df[\"latency\"].std()))\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "    def print(self):\n",
    "        print(self.EXPERIMENT_DIRNAME)\n",
    "        print(self.RAMP_UP_DURATION)\n",
    "        print(self.RAMP_DOWN_DURATION)\n",
    "        print(self.OUTPUT_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(os.path.join(os.path.abspath(\"\"), '..', 'data', 'BuzzBlogBenchmark_2022-04-14-05-26-13')):\n",
    "    raise FileNotFoundError(\"Input Directory not found\")\n",
    "if not os.path.isdir(os.path.join(os.path.abspath(\"\"), '..', 'data', 'BBB_2')):\n",
    "    os.mkdir(os.path.join(os.path.abspath(\"\"), '..', 'data', 'BBB_2'))\n",
    "    os.mkdir(os.path.join(os.path.abspath(\"\"), '..', 'data', 'BBB_2', 'rpc'))\n",
    "    os.mkdir(os.path.join(os.path.abspath(\"\"), '..', 'data', 'BBB_2', 'rpc', 'latency_distribution'))\n",
    "    os.mkdir(os.path.join(os.path.abspath(\"\"), '..', 'data', 'BBB_2', 'rpc', 'pit'))\n",
    "    os.mkdir(os.path.join(os.path.abspath(\"\"), '..', 'data', 'BBB_2', 'queue'))\n",
    "    os.mkdir(os.path.join(os.path.abspath(\"\"), '..', 'data', 'BBB_2', 'cpu'))\n",
    "exp = Experiment('BuzzBlogBenchmark_2022-04-14-05-26-13', 180, 60, 'BBB_2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loadgen Request Caching Start...\n",
      "Loadgen Request Cache Complete.\n",
      "RPC Request Caching Start...\n",
      "RPC Request Cache Complete.\n",
      "TCP Backlog Cache Start...\n",
      "TCP Backlog Cache Complete.\n",
      "CPU Collectl Caching Start...\n",
      "CPU Collectl Caching Complete.\n"
     ]
    }
   ],
   "source": [
    "# exp.print()\n",
    "exp.cache_request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             pid     command  len  max node_name  window_1000  window_10\n",
      "timestamp                                                               \n",
      "-48.758224     0   swapper/0    0  128   node-15     -49000.0   -48760.0\n",
      "-35.520546     0   swapper/2    0  128   node-15     -36000.0   -35520.0\n",
      "-35.515812     0   swapper/3    0  128   node-13     -36000.0   -35520.0\n",
      "-35.505121     0   swapper/3    0  128    node-9     -36000.0   -35510.0\n",
      "-23.723498     0  swapper/15    0  128    node-5     -24000.0   -23720.0\n",
      "...          ...         ...  ...  ...       ...          ...        ...\n",
      " 741.824322    0   swapper/1    0  128   node-14     742000.0   741820.0\n",
      " 741.907852    0   swapper/2    0  128   node-15     742000.0   741910.0\n",
      " 741.954999    0   swapper/2    0  128   node-16     742000.0   741950.0\n",
      " 742.013523    0   swapper/3    0  128   node-17     742000.0   742010.0\n",
      " 742.069136    0   swapper/3    0  128   node-18     742000.0   742070.0\n",
      "\n",
      "[12963308 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(exp.bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               pid    command  len  max node_name  window_1000  window_10\n",
      "timestamp                                                                \n",
      "-35.505121       0  swapper/3    0  128    node-9     -36000.0   -35510.0\n",
      " 0.012022        0  swapper/1    0  128    node-9          0.0       10.0\n",
      " 0.035546        0  swapper/1    0  128    node-9          0.0       40.0\n",
      " 0.043854        0  swapper/3    0  128    node-9          0.0       40.0\n",
      " 0.091903        0  swapper/1    0  128    node-9          0.0       90.0\n",
      "...            ...        ...  ...  ...       ...          ...        ...\n",
      " 170.466638      0  swapper/1    0  128    node-9     170000.0   170470.0\n",
      " 170.532875      0  swapper/2    0  128    node-9     171000.0   170530.0\n",
      " 227.286312      0  swapper/3    0  128    node-9     227000.0   227290.0\n",
      " 528.274529  20604   postgres    0  128    node-9     528000.0   528270.0\n",
      " 741.542077      0  swapper/2    0  128    node-9     742000.0   741540.0\n",
      "\n",
      "[1031 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(exp.bl[exp.bl['node_name'] == 'node-9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/users/abhishar/disk/BuzzBlogBenchmark-1/analysis/notebooks/ListLikes.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bapt064.apt.emulab.net/users/abhishar/disk/BuzzBlogBenchmark-1/analysis/notebooks/ListLikes.ipynb#ch0000009vscode-remote?line=0'>1</a>\u001b[0m exp\u001b[39m.\u001b[39;49msuccess_fail_metric()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bapt064.apt.emulab.net/users/abhishar/disk/BuzzBlogBenchmark-1/analysis/notebooks/ListLikes.ipynb#ch0000009vscode-remote?line=1'>2</a>\u001b[0m exp\u001b[39m.\u001b[39mrw_metric()\n",
      "\u001b[1;32m/users/abhishar/disk/BuzzBlogBenchmark-1/analysis/notebooks/ListLikes.ipynb Cell 1'\u001b[0m in \u001b[0;36mExperiment.success_fail_metric\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bapt064.apt.emulab.net/users/abhishar/disk/BuzzBlogBenchmark-1/analysis/notebooks/ListLikes.ipynb#ch0000000vscode-remote?line=134'>135</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msuccess_fail_metric\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bapt064.apt.emulab.net/users/abhishar/disk/BuzzBlogBenchmark-1/analysis/notebooks/ListLikes.ipynb#ch0000000vscode-remote?line=135'>136</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloadgen_requests[(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloadgen_requests\u001b[39m.\u001b[39;49mindex \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mRAMP_UP_DURATION)]\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bapt064.apt.emulab.net/users/abhishar/disk/BuzzBlogBenchmark-1/analysis/notebooks/ListLikes.ipynb#ch0000000vscode-remote?line=136'>137</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloadgen_requests[(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloadgen_requests\u001b[39m.\u001b[39mindex \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \\\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bapt064.apt.emulab.net/users/abhishar/disk/BuzzBlogBenchmark-1/analysis/notebooks/ListLikes.ipynb#ch0000000vscode-remote?line=137'>138</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloadgen_requests\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mmax() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mRAMP_DOWN_DURATION)]\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bapt064.apt.emulab.net/users/abhishar/disk/BuzzBlogBenchmark-1/analysis/notebooks/ListLikes.ipynb#ch0000000vscode-remote?line=138'>139</a>\u001b[0m     df_temp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf\u001b[39m.\u001b[39mgroupby([\u001b[39m\"\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39mcount()[\u001b[39m\"\u001b[39m\u001b[39mmethod\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "exp.success_fail_metric()\n",
    "exp.rw_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.lat_distr()\n",
    "# exp.pit_graph()\n",
    "# exp.thput_graph()\n",
    "# exp.print_summary()\n",
    "# exp.rpc()\n",
    "exp.server_queue()\n",
    "# exp.server_cpu()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3351dec5579986d6f1a0b93da217d89e0ac97380e1217784cab03325207244a6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('bbb_pyenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
