{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c083af10",
   "metadata": {},
   "source": [
    "# rAdvisor graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efd10af",
   "metadata": {},
   "source": [
    "## Notebook inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc069d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Name of the directory in `../data`\n",
    "EXPERIMENT_DIRNAME = \"BuzzBlogBenchmark_2021-10-10-18-35-22\"\n",
    "# Name of the directory in `../data/{experiment_dirname}/logs`\n",
    "NODE_NAME = \"pc715.emulab.net\"\n",
    "# Docker container ID to parse statistics for\n",
    "# This can be the short (12 chars) or long (64 chars) ID;\n",
    "# it is used as a prefix when matching against the log files.\n",
    "CONTAINER_ID = \"5e43e14129c7\"\n",
    "\n",
    "# This should be one of:\n",
    "# - \"blkio.service.bytes\"\n",
    "# - \"blkio.throttle.service.bytes\"\n",
    "# - \"blkio.bfq.service.bytes\"\n",
    "# Which key has actual data depends on the configuration of the system.\n",
    "# More info:\n",
    "# https://github.com/elba-docker/radvisor/blob/develop/docs/collecting.md#additional-blkio-entries\n",
    "# https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v1/blkio-controller.html\n",
    "# https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/resource_management_guide/ch-subsystems_and_tunable_parameters#sec-blkio\n",
    "IO_SERIES_KEY = \"blkio.throttle.service.bytes\"\n",
    "\n",
    "# Collection interval, displayed on graphs\n",
    "INTERVAL = \"50ms\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dbcbc9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad6a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lib.radvisor_parser as radvisor_parser\n",
    "import math\n",
    "import tarfile\n",
    "import io\n",
    "from typing import List, Iterable, Tuple, Dict, Any, Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85d9cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_percpu_value(a: List[int], b: List[int]) -> List[int]:\n",
    "    return [max(a - b, 0) for (a, b) in zip(a, b)]\n",
    "\n",
    "def diff_percpu(r):\n",
    "    \"\"\"Adapted from https://stackoverflow.com/questions/53808042/pandas-diff-but-user-defined-function\"\"\"\n",
    "    return [np.NaN] + [diff_percpu_value(r[n + 1], r[n]) for n in range(r.shape[0] - 1)]\n",
    "\n",
    "def construct_dataframe(log_file: Iterable[str]) -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Constructs a dataframe containing all of the parsed rAdvisor log data,\n",
    "    including a couple of additional columns with derived data that are used for analysis.\n",
    "    Additionally, returns the YAML metadata included at the top of the log file.\n",
    "    \"\"\"\n",
    "\n",
    "    log_iter, metadata = radvisor_parser.parse_target_log(log_file)\n",
    "    dataframe = pd.DataFrame(log_iter)\n",
    "\n",
    "    # Construct other series as needed for analysis\n",
    "    min_timestamp = dataframe[\"read\"].min()\n",
    "    # Normalize timestamps by subtracting minimum\n",
    "    dataframe[\"time\"] = dataframe.apply(lambda r: (r[\"read\"] - min_timestamp), axis=1)\n",
    "    dataframe[\"time_diff\"] = dataframe[\"time\"].diff()\n",
    "    dataframe[\"percpu_diff\"] = diff_percpu(dataframe[\"cpu_usage_percpu\"])\n",
    "    # All log entry keys have their \".\"'s converted to \"_\";'s when imported\n",
    "    io_series_key_corrected = IO_SERIES_KEY.replace('.', '_')\n",
    "    dataframe[\"read\"] = dataframe[io_series_key_corrected].apply(lambda i: i['read'])\n",
    "    dataframe[\"write\"] = dataframe[io_series_key_corrected].apply(lambda i: i['write'])\n",
    "    dataframe[\"read_diff\"] = dataframe[\"read\"].diff().apply(lambda v: max(v, 0))\n",
    "    dataframe[\"write_diff\"] = dataframe[\"write\"].diff().apply(lambda v: max(v, 0))\n",
    "\n",
    "    return (dataframe, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac02a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "tarball_path = os.path.join(os.pardir, \"data\", EXPERIMENT_DIRNAME, \"logs\", NODE_NAME, \"radvisor.tar.gz\")\n",
    "with tarfile.open(tarball_path, \"r:gz\") as tar:\n",
    "    container_log_filepath= None\n",
    "    for filepath in tar.getnames():\n",
    "        base_filename = os.path.basename(filepath)\n",
    "        if base_filename.startswith(CONTAINER_ID) and base_filename.endswith(\".log\"):\n",
    "            container_log_filepath = filepath\n",
    "            break\n",
    "    \n",
    "    if not container_log_filepath:\n",
    "        raise Exception(f\"Could not find container log file with prefix {CONTAINER_ID}\"\n",
    "                        f\" in tarball at {tarball_path}; all files in archive: {tar.getnames()}\")\n",
    "\n",
    "    with tar.extractfile(container_log_filepath) as log_file_byte_reader:\n",
    "        # rAdvisor, written in Rust, always uses and outputs UTF-8 text\n",
    "        log_file_string_reader = io.TextIOWrapper(log_file_byte_reader, encoding=\"utf-8\")\n",
    "        dataframe, metadata = construct_dataframe(log_file_string_reader)\n",
    "        print(f\"Generated dataframe for '{metadata['Metadata']['Names'][0]}' ({metadata['Metadata']['Id']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2a6176",
   "metadata": {},
   "source": [
    "## Point-in-time / line graphs\n",
    "\n",
    "- CPU (per-cpu rolled up into single time-series) - `cpu.usage.percpu`\n",
    "- Memory - `memory.usage.current`\n",
    "- I/O (read, write) - `blkio.service.bytes.read`, `blkio.service.bytes.write`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e22dda6",
   "metadata": {},
   "source": [
    "### CPU Point-in-time / line graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100f5d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph inputs\n",
    "\n",
    "# Size of the window to aggregate collection samples in.\n",
    "WINDOW_SIZE_MS = 1_000\n",
    "\n",
    "# Aggregation function used for windows.\n",
    "WINDOW_AGGREGATION_FUNCTION = max\n",
    "\n",
    "# The aggregation function used to aggregate\n",
    "# each \"CPU time consumed per-core\" time-series for a single collection sample\n",
    "# into a single \"CPU time consumed\" time-series.\n",
    "# If using average, make sure to filter unused CPU cores;\n",
    "# otherwise the average might be artificially depressed\n",
    "# by a handful of permenant zeroes\n",
    "PER_CPU_AGGREGATION_FUNCTION = max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054db325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cpu_series(dataframe: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Generates the CPU time-series by aggregating the data.\n",
    "    This mutates the dataframe by adding additional columns.\n",
    "    \"\"\"\n",
    "    window_size_ns = int(WINDOW_SIZE_MS * 1e6)\n",
    "    dataframe[\"cpu_diff\"] = dataframe[\"percpu_diff\"].apply(\n",
    "        lambda d: PER_CPU_AGGREGATION_FUNCTION(d) if type(d) is list and d else 0)\n",
    "    dataframe[\"cpu\"] = dataframe.apply(\n",
    "        lambda r: (r[\"cpu_diff\"] / r[\"time_diff\"] if r[\"time_diff\"] != 0 else 0), axis=1)\n",
    "    dataframe[\"cpu_window\"] = dataframe.apply(lambda r: r[\"time\"] // window_size_ns, axis=1)\n",
    "    cpu_series = dataframe.groupby([\"cpu_window\"])[\"cpu\"].agg(WINDOW_AGGREGATION_FUNCTION)\n",
    "    # Convert the series index from window indices to seconds\n",
    "    cpu_series.index = cpu_series.index.map(lambda i: i * (WINDOW_SIZE_MS / float(1e3)))\n",
    "    # Convert to core-percentage\n",
    "    cpu_series = cpu_series.apply(lambda v: v * 100)\n",
    "\n",
    "    return cpu_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5c96c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_series = generate_cpu_series(dataframe)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10, 5)\n",
    "max_time = cpu_series.index.max()\n",
    "cpu_series.plot(ax=ax, kind=\"line\", grid=True)\n",
    "ax.set_xlim((0, max_time))\n",
    "ax.set_ylim((0, 100))\n",
    "ax.grid(b=True, alpha=0.75)\n",
    "ax.set_title(f\"CPU Utilization ({WINDOW_SIZE_MS / 1e3:.1f}s window)\")\n",
    "ax.set_xlabel(\"Time (seconds)\")\n",
    "ax.set_ylabel(f\"Aggregated CPU per window (%)\")\n",
    "ax.set_yticks(range(0, 101, 10))\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b27c7c",
   "metadata": {},
   "source": [
    "### Memory Point-in-time / line graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd74db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph inputs\n",
    "\n",
    "# Size of the window to aggregate collection samples in.\n",
    "WINDOW_SIZE_MS = 1_000\n",
    "\n",
    "# Aggregation function used for windows.\n",
    "WINDOW_AGGREGATION_FUNCTION = np.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df7d9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_memory_series(dataframe: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Generates the Memory time-series by aggregating the data.\n",
    "    This mutates the dataframe by adding additional columns.\n",
    "    \"\"\"\n",
    "    window_size_ns = int(WINDOW_SIZE_MS * 1e6)\n",
    "    dataframe[\"memory_window\"] = dataframe.apply(lambda r: r[\"time\"] // window_size_ns, axis=1)\n",
    "    memory_series = dataframe.groupby([\"memory_window\"])[\"memory_usage_current\"].agg(WINDOW_AGGREGATION_FUNCTION)\n",
    "    # Convert the series index from window indices to seconds\n",
    "    memory_series.index = memory_series.index.map(lambda i: i * (WINDOW_SIZE_MS / float(1e3)))\n",
    "    # Convert to MiB\n",
    "    memory_series = memory_series.apply(lambda v: v / (1024 * 1024))\n",
    "\n",
    "    return memory_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b200e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_series = generate_memory_series(dataframe)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10, 5)\n",
    "max_time = memory_series.index.max()\n",
    "max_memory = memory_series.max()\n",
    "memory_series.plot(ax=ax, kind=\"line\", grid=True)\n",
    "ax.set_xlim((0, max_time))\n",
    "ax.set_ylim((0, max_memory))\n",
    "ax.grid(b=True, alpha=0.75)\n",
    "ax.set_title(f\"Memory usage ({WINDOW_SIZE_MS / 1e3:.1f}s window)\")\n",
    "ax.set_xlabel(\"Time (seconds)\")\n",
    "ax.set_ylabel(f\"Memory used (MiB)\")\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2708cbb4",
   "metadata": {},
   "source": [
    "### I/O (Read, Write) Point-in-time / line graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301178a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph inputs\n",
    "\n",
    "# Size of the window to aggregate collection samples in.\n",
    "WINDOW_SIZE_MS = 1_000\n",
    "\n",
    "# Aggregation function used for windows.\n",
    "WINDOW_AGGREGATION_FUNCTION = sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1c3c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_io_series(dataframe: pd.DataFrame, metric: Literal[\"read\", \"write\"]) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Generates the IO time-series by aggregating the data.\n",
    "    This mutates the dataframe by adding additional columns.\n",
    "    \"\"\"\n",
    "    window_size_ns = int(WINDOW_SIZE_MS * 1e6)\n",
    "    dataframe[f\"io_{metric}_window\"] = dataframe.apply(lambda r: r[\"time\"] // window_size_ns, axis=1)\n",
    "    io_series = dataframe.groupby([f\"io_{metric}_window\"])[f\"{metric}_diff\"].agg(WINDOW_AGGREGATION_FUNCTION)\n",
    "    # Convert the series index from window indices to seconds\n",
    "    io_series.index = io_series.index.map(lambda i: i * (WINDOW_SIZE_MS / float(1e3)))\n",
    "    # Convert to KiB\n",
    "    io_series = io_series.apply(lambda v: v / 1024)\n",
    "\n",
    "    return io_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec818c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "io_series = {\n",
    "    \"read\": generate_io_series(dataframe, \"read\"),\n",
    "    \"write\": generate_io_series(dataframe, \"write\"),\n",
    "}\n",
    "\n",
    "# Use the same max time for both plots\n",
    "max_time = max(series.index.max() for series in io_series.values())\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "for (idx, (metric, series)) in enumerate(io_series.items()):\n",
    "    ax = fig.add_subplot(2, 1, idx + 1)\n",
    "    max_io = series.max()\n",
    "    series.plot(ax=ax, kind=\"line\", grid=True)\n",
    "    ax.set_xlim((0, max_time))\n",
    "    ax.set_ylim((0, max(max_io, 1)))\n",
    "    ax.grid(b=True, alpha=0.75)\n",
    "    ax.set_title(f\"I/O {metric}s ({WINDOW_SIZE_MS / 1e3:.1f}s window)\")\n",
    "    ax.set_xlabel(\"Time (seconds)\")\n",
    "    ax.set_ylabel(f\"Data transferred (KiB)\")\n",
    "fig.tight_layout(h_pad=1.2)\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef110ae",
   "metadata": {},
   "source": [
    "## Histograms\n",
    "\n",
    "- CPU (per-cpu rolled up into single time-series) - `cpu.usage.percpu`\n",
    "- Memory - `memory.usage.current`\n",
    "- I/O (read, write) - `blkio.service.bytes.read`, `blkio.service.bytes.write`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2865bc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_histogram_series(src_series: pd.Series, bin_width: float) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Generates a series containing the same number of points as src_series,\n",
    "    where each value is the lower bin bound that the corresponding point belongs to.\n",
    "    \"\"\"\n",
    "    bin_indices = (src_series\n",
    "        .apply(lambda r: r // bin_width)\n",
    "        .dropna()\n",
    "        .apply(lambda r: int(r)))\n",
    "    bin_lower_bounds = bin_indices.apply(lambda r: r * bin_width)\n",
    "    return bin_lower_bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b26b5d",
   "metadata": {},
   "source": [
    "### CPU Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2a20a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph inputs\n",
    "\n",
    "# Size of the bins (in CPU-%) used to group data points.\n",
    "CPU_UTIL_PERCENT_BIN_SIZE = 2\n",
    "\n",
    "# The aggregation function used to aggregate\n",
    "# each \"CPU time consumed per-core\" time-series for a single collection sample\n",
    "# into a single \"CPU time consumed\" time-series.\n",
    "# If using average, make sure to filter unused CPU cores;\n",
    "# otherwise the average might be artificially depressed\n",
    "# by a handful of permenant zeroes\n",
    "PER_CPU_AGGREGATION_FUNCTION = max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18109069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cpu_histogram_series(dataframe: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Generates the CPU histogram data by aggregating the data.\n",
    "    This mutates the dataframe by adding additional columns.\n",
    "    \"\"\"\n",
    "    dataframe[\"cpu_histogram_diff\"] = dataframe[\"percpu_diff\"].apply(\n",
    "        lambda d: PER_CPU_AGGREGATION_FUNCTION(d) if type(d) is list and d else 0)\n",
    "    cpu_series = dataframe.apply(\n",
    "        lambda r: (r[\"cpu_histogram_diff\"] / r[\"time_diff\"] if r[\"time_diff\"] != 0 else 0), axis=1)\n",
    "    cpu_series = cpu_series.reindex(range(0, cpu_series.index.max() + 1))\n",
    "    # Convert to core-percentage\n",
    "    cpu_series = cpu_series.apply(lambda v: v * 100)\n",
    "    return cpu_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699488b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_series = generate_cpu_histogram_series(dataframe)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10, 5)\n",
    "cpu_series.plot(ax=ax, kind='hist', edgecolor='white', linewidth=1.2,\n",
    "    bins=math.ceil((cpu_series.max() - cpu_series.min()) / CPU_UTIL_PERCENT_BIN_SIZE))\n",
    "ax.grid(b=True, alpha=0.75, axis='y')\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_title(f\"CPU Utilization Distribution (for utilization each {INTERVAL})\")\n",
    "ax.set_xlabel(\"CPU Utilization (%)\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8614955",
   "metadata": {},
   "source": [
    "### Memory Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28d7f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph inputs\n",
    "\n",
    "# Size of the bins (in MiB) used to group data points.\n",
    "MEMORY_MIB_BIN_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfafd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_memory_histogram_series(dataframe: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Generates the Memory histogram data by aggregating the data.\n",
    "    This mutates the dataframe by adding additional columns.\n",
    "    \"\"\"\n",
    "    # Convert to MiB\n",
    "    memory_series = dataframe[\"memory_usage_current\"].apply(lambda v: v / (1024 * 1024))\n",
    "    return memory_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5548ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_series = generate_memory_histogram_series(dataframe)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10, 5)\n",
    "memory_series.plot(ax=ax, kind='hist', edgecolor='white', linewidth=1.2,\n",
    "    bins=math.ceil((memory_series.max() - memory_series.min()) / MEMORY_MIB_BIN_SIZE))\n",
    "ax.grid(b=True, alpha=0.75, axis='y')\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_title(f\"Memory Usage Distribution (for measurements collected each {INTERVAL})\")\n",
    "ax.set_xlabel(\"Memory Usage (MiB)\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5493996",
   "metadata": {},
   "source": [
    "### I/O (Read, Write) Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d95a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph inputs\n",
    "\n",
    "# Number of bins to use when plotting the IO data\n",
    "IO_NUM_BINS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e4d6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_io_histogram_series(dataframe: pd.DataFrame, metric: Literal[\"read\", \"write\"]) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Generates the IO time-series by aggregating the data.\n",
    "    This mutates the dataframe by adding additional columns.\n",
    "    \"\"\"\n",
    "    # Convert to KiB\n",
    "    io_series = dataframe[f\"io_{metric}_window\"].apply(lambda v: v / 1024)\n",
    "    return io_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e1775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "io_histogram_series = {\n",
    "    \"read\": generate_io_histogram_series(dataframe, \"read\"),\n",
    "    \"write\": generate_io_histogram_series(dataframe, \"write\"),\n",
    "}\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "for (idx, (metric, series)) in enumerate(io_series.items()):\n",
    "    ax = fig.add_subplot(2, 1, idx + 1)\n",
    "    series.plot(ax=ax, kind='hist', edgecolor='white', linewidth=1.2, bins=IO_NUM_BINS)\n",
    "    ax.grid(b=True, alpha=0.75, axis='y')\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_title(f\"I/O {metric.capitalize()} Distribution (for data transferred in {INTERVAL})\")\n",
    "    ax.set_xlabel(\"Data transferred (KiB)\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "fig.tight_layout(h_pad=1.2)\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdd7950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c0856d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "radvisor-analysis-notebooks-kernel",
   "language": "python",
   "name": "radvisor-analysis-notebooks-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
